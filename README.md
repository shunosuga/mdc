# Make Data Count - Finding Data References
> Kaggleコンペティション: 科学論文からのデータ引用検出

## コンペティション概要

### 背景と目的
Make Data Count（MDC）は、科学データの価値を正当に評価することを目指すグローバルな取り組みです。科学データは発見やイノベーションの基盤となっているにも関わらず、その価値が過小評価されているのが現状です。

このコンペティションの目的は、**科学論文のフルテキストから研究データへの引用を自動的に検出し、その種類を分類する高性能なモデル**を開発することです。開発されたモデルは、MDCデータ引用コーパスに高品質で文脈化されたデータと論文の関連性を継続的に追加するために使用されます。

### タスクの詳細
科学文献のフルテキストから**データ引用（研究データへの参照）**を特定し、引用の種類をタグ付けします：

- **Primary（一次データ）**: その論文の研究のために特別に生成された生データまたは処理済みデータ
- **Secondary（二次データ）**: 既存の記録や公開データから派生または再利用された生データまたは処理済みデータ

### なぜこの問題が重要で困難なのか
現在のデータ引用システムでは、研究データの約86%が「引用されていない」状態にあります（Peters et al., 2016）。これは以下の理由によります：

1. **多様な言及方法**: 著者は以下のような様々な方法でデータに言及します
   - メソッドセクションでの詳細な説明
   - 論文の他の部分での間接的な言及
   - 参考文献リストでの正式な引用

2. **可変的な表現**: 著者はデータと論文の関係を表現する際に様々な言語を使用します
   - 「publicly available（公開されている）」
   - 「obtained from（〜から取得）」など

3. **プログラマティックな識別の困難さ**: 自然言語での記述のため、自動化が困難

## 評価指標とデータ

### 評価指標
**F1スコア**が使用されます。F1スコアは情報検索でよく使われる指標で、精度（Precision）と再現率（Recall）の調和平均です：

- **Precision（精度）**: 予測した陽性のうち実際に陽性だった割合
- **Recall（再現率）**: 実際の陽性のうち正しく予測できた割合

F1スコアは精度と再現率を等しく重み付けするため、どちらもバランスよく高い性能が求められます。

### 提出形式
テストデータセット内のデータ引用を特定し、以下の形式で提出します：

```csv
row_id,article_id,dataset_id,type
0,10.1002_cssc.202201821,https://doi.org/10.5281/zenodo.7074790,Primary
1,10.1002_esp.5090,CHEMBL1097,Secondary
```

**重要な注意点：**
- 同じarticle_idとdataset_id、typeの組み合わせは一度だけ予測
- データ引用が含まれる論文のみ提出に含める
- データ引用がない論文を含めると偽陽性としてペナルティ
- DOIは完全なフォーマット（https://doi.org/[prefix]/[suffix]）で提出

## コンペティション詳細

### スケジュール
- **開始日**: 2025年6月11日
- **エントリー締切**: 2025年9月2日
- **チーム合併締切**: 2025年9月2日
- **最終提出締切**: 2025年9月9日

### 賞金
- 1位: $40,000
- 2位: $20,000  
- 3位: $17,000
- 4位: $13,000
- 5位: $10,000

### 提出要件
- **Notebook形式**での提出が必須
- **実行時間制限**: CPU/GPU共に9時間以内
- **インターネットアクセス**: 無効
- **外部データ**: 自由に利用可能な公開データ（事前訓練モデル含む）の使用可
- **提出ファイル名**: submission.csv

### スポンサー
The Navigation FundとChan Zuckerberg Initiativeの支援により実施されています。

---

## 解法アプローチ

### 全体戦略
このタスクは主に以下の3つのステップに分解できます：

1. **PDFパース**: 科学論文PDFからテキストを抽出
2. **データ引用マイニング**: テキストからデータ引用を検出
3. **分類**: 検出されたデータ引用をPrimary/Secondaryに分類

### 1. PDFパースアプローチ

#### 検討ツール
- **marker**: Markdown形式で出力、GPUを使用、高品質だが処理時間が長い
- **PyMuPDF**: 軽量で高速、CPUのみで動作
- **その他**: pdfplumber、Tika等

#### 戦略
- 品質と処理時間のトレードオフを考慮
- Kaggleの制約（9時間実行時間）を考慮した選択が重要
- テキスト抽出の品質がダウンストリームタスクに大きく影響

### 2. データ引用マイニング

#### 正規表現ベースアプローチ
**利点:**
- 高速で確実
- 明確なパターンを持つ引用（DOI等）に効果的
- ローカル環境での検証が容易

**課題:**
- 複雑な自然言語表現への対応が困難
- 新しいパターンへの適応が困難

#### ターゲットパターン
1. **DOI**: `10.xxxx/yyyy` 形式
2. **データベース名**: CHEMBL、PDB、GenBankなど
3. **URL**: データリポジトリへの直接リンク
4. **データセット名**: 論文中で明示的に言及されるデータセット

#### 検証戦略
- MDCが公開している既存データでの精度検証
- 取得できる引用と取得できない引用の分析
- 偽陽性・偽陰性の詳細分析

### 3. LLMによる分類（必要に応じて）

#### 使用タイミング
- 正規表現だけでは十分な精度が得られない場合
- ただし、1位解法によるとCPUオンリー・LLM不使用でも0.57のF1スコアが達成可能

#### Few-shot学習の最適化
- **ショット数**: 多いほど良い（過去コンペの教訓）
- **フォーマット**: `{"user": "", "assistant": ""}` 形式を推奨
- **コンテキスト**: 引用周辺の適切な文脈長の選択

#### コンテキスト設計
- データ引用周辺の文脈をどの程度含めるか
- セクション情報（Methods、Results等）の活用
- 論文全体の構造を考慮した情報抽出

## 開発計画

### フェーズ1: 基盤構築（ローカル環境）
1. **データ理解**
   - 訓練データの詳細分析
   - ラベル分布の把握
   - 論文の種類・分野の分析

2. **正規表現エンジンの開発**
   - 基本的なDOIパターンの実装
   - データベース名の検出ロジック
   - 複雑なパターンへの対応

3. **評価システムの構築**
   - ローカルでのF1スコア計算
   - 詳細な誤分析システム
   - パフォーマンス測定

### フェーズ2: 精度向上
1. **正規表現の最適化**
   - パターンの拡張と精密化
   - 偽陽性の削減
   - 再現率の向上

2. **マルチパターン統合**
   - 複数の検出手法の組み合わせ
   - 信頼度スコアの導入
   - 結果の統合戦略

### フェーズ3: 高度な手法（必要に応じて）
1. **LLM統合**
   - 軽量なモデルの選択
   - プロンプトエンジニアリング
   - 効率的な推論戦略

2. **アンサンブル手法**
   - 複数アプローチの組み合わせ
   - 重み付き投票
   - 信頼度ベースの選択

### フェーズ4: Kaggle対応
1. **Notebook化**
   - 実行時間の最適化
   - メモリ使用量の最適化
   - 外部データの統合

2. **提出準備**
   - 出力フォーマットの確認
   - エラーハンドリングの追加
   - 最終検証

## 技術的考慮事項

### パフォーマンス最適化
- **並列処理**: PDFパースや推論の並列化
- **メモリ管理**: 大きなPDFファイルの効率的な処理
- **キャッシュ**: 中間結果の保存と再利用

### エラーハンドリング
- **PDF読み込み失敗**: 破損ファイルへの対応
- **パース失敗**: 代替手法への自動切り替え
- **予期しない形式**: ロバストな処理ロジック

### 評価とデバッグ
- **段階的評価**: 各ステップでの精度測定
- **ログ出力**: 詳細な処理ログの記録
- **可視化**: 結果の視覚的分析

### リソース制約対応
- **CPU効率**: 軽量なアルゴリズムの選択
- **メモリ効率**: ストリーミング処理の導入
- **時間効率**: 処理時間の見積もりと最適化

## 期待される成果

### 短期目標
- 正規表現ベースでF1スコア0.4-0.5の達成
- 主要なデータ引用パターンの90%以上をカバー
- 安定した処理パイプラインの構築

### 中期目標  
- 高度な手法の統合によりF1スコア0.6-0.7の達成
- 多様な論文分野への適応
- エラー率の最小化

### 最終目標
- 上位入賞レベルの精度達成
- 実用的な処理速度の実現
- 再現可能で拡張可能なソリューション

---

## 参考情報

### データソース
- **コンペティションデータ**: PDF + XML形式の科学論文
- **外部データ**: MDC公開データ、事前訓練モデル等

### 関連研究
- データ引用に関する既存研究
- 科学文献マイニングの手法
- 情報抽出とNLPの最新動向

### ツールとライブラリ
- **PDF処理**: marker, PyMuPDF, pdfplumber
- **NLP**: transformers, spaCy, nltk
- **ML**: scikit-learn, xgboost, lightgbm
- **評価**: pandas, numpy, matplotlib
