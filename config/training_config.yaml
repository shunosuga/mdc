# ModernBERT Training Configuration

# Model configuration
model:
  model_name: "answerdotai/ModernBERT-base"
  num_labels: 2  # Binary classification: 0=normal, 1=data_identifier
  dropout: 0.1
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1

# Data configuration
data:
  train_data_path: "training_data/bert_samples.jsonl"
  validation_split: 0.2  # 20% for validation
  max_length: 128  # Maximum sequence length
  batch_size: 16
  shuffle_train: true
  shuffle_seed: 42

# Training configuration
training:
  output_dir: "models/modernbert_data_identifier"
  num_epochs: 3
  learning_rate: 2.0e-5
  warmup_ratio: 0.1
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
  # Scheduler
  lr_scheduler_type: "linear"  # "linear", "cosine", "polynomial"
  
  # Early stopping
  early_stopping: true
  early_stopping_patience: 3
  early_stopping_threshold: 0.01

# Hardware configuration
hardware:
  device: "auto"  # "auto", "cuda", "cpu"
  mixed_precision: true  # Use fp16 if available
  dataloader_num_workers: 2
  dataloader_pin_memory: true

# Evaluation configuration
evaluation:
  eval_steps: 500  # Evaluate every N steps
  eval_strategy: "steps"  # "steps" or "epoch"
  save_steps: 500  # Save checkpoint every N steps
  save_strategy: "steps"  # "steps" or "epoch"
  save_total_limit: 3  # Keep only 3 best checkpoints
  load_best_model_at_end: true
  metric_for_best_model: "eval_f1"
  greater_is_better: true

# Logging configuration
logging:
  logging_dir: "logs/modernbert_training"
  logging_steps: 100
  report_to: []  # ["tensorboard", "wandb"] if needed
  log_level: "info"
  verbose: true

# Reproducibility
seed: 42

# Advanced training options
advanced:
  gradient_checkpointing: false  # Save memory at cost of speed
  push_to_hub: false  # Push model to HuggingFace Hub
  hub_model_id: null  # Model ID for hub
  
  # Custom loss weighting (optional)
  class_weights: null  # [1.0, 1.0] for balanced, or [0.3, 0.7] for weighted
  
  # Data augmentation
  augmentation:
    enabled: false
    dropout_prob: 0.1